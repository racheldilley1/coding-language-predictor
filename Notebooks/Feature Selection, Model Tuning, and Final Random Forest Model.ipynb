{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import joblib\n",
    "\n",
    "# sql\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "#modeling\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from classification_functions import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "%config InlineBackend.figure_formats = ['retina']  # or svg\n",
    "%matplotlib inline\n",
    "\n",
    "#warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "colors = ['#e898ac', '#00cfcc', '#ff9973', '#002845']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final model functions and scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(X_train, y_train):\n",
    "    '''\n",
    "    A fucntion for fitting random forest model\n",
    "    performs randomized cross validation search to find optimal hyperparameters\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    prints cross validation classification metrics and params \n",
    "    returns random forest model \n",
    "    '''\n",
    "    rf = RandomForestClassifier()\n",
    "    #params to search\n",
    "    rand_param = {\n",
    "                    'n_estimators': [800, 1500],\n",
    "                    'max_features': ['sqrt'],\n",
    "                    'max_depth' : [ 8, 15, 20],\n",
    "                    'min_samples_leaf': [3, 5],\n",
    "                    'min_samples_split': [6, 10]\n",
    "                }\n",
    "    rs = RandomizedSearchCV(rf, param_distributions= rand_param, cv=5, n_iter=10, n_jobs=-1)\n",
    "    rs.fit(X_train, y_train)\n",
    "    \n",
    "    f1 = round(cross_val_score(rs, X_train, y_train, scoring='f1_macro', cv=5).mean(), 2)\n",
    "    print(f'Random Forest with params:\\n')\n",
    "    print(rs.best_params_)\n",
    "    print(f'Has an f1 score of: {f1}')\n",
    "          \n",
    "    return rs\n",
    "\n",
    "def rf_baseline(X_train, y_train):\n",
    "    '''\n",
    "    A function that fits and returns a baseline xgboost model\n",
    "    '''          \n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_train, y_train)\n",
    "          \n",
    "    return rf\n",
    "\n",
    "def get_cv_f1(model, X_val, y_val):\n",
    "    '''\n",
    "    function that returns f1 score\n",
    "    '''\n",
    "    preds = model.predict(X_val)\n",
    "    return f1_score( y_val, preds, average=\"macro\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create engine\n",
    "engine = create_engine('postgresql://racheldilley:localhost@localhost:5432/programer_database')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT \"Hobbyist\", \"Age\", \"Age1stCode\", \"Country\", \"EdLevel\", \"Ethnicity\",\n",
    "       \"Gender\", \"OpSys\", \"UndergradMajor\", \"YearsCode\", \"YearsCodePro\",\n",
    "       \"database_count\", \"back-end\", \"full-stack\", \"front-end\", \"desktop\",\n",
    "       \"mobile\", \"DevOps\", \"Database admin\", \"Designer\", \"System admin\",\n",
    "       \"Student\", \"Other Occupation\", \"Retired Dev\", \"Sometimes Code at Work\", \"Region\",\n",
    "       \"JavaScript\", \"Python\", \"SQL\", \"Java\" , \"HTML/CSS\"\n",
    "FROM cleaned_survey_data6\n",
    "'''\n",
    "df = pd.read_sql_query(query, engine)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['database_count', 'Age1stCode', 'YearsCodePro', 'Age','YearsCode', 'EdLevel', \n",
    "         'Gender', 'UndergradMajor', 'Region', \n",
    "        'Hobbyist', 'back-end', 'full-stack', 'front-end', 'desktop', 'mobile', 'DevOps', 'Database admin', \n",
    "        'Designer','System admin', 'Student', 'Other Occupation', 'Retired Dev','Sometimes Code at Work', \n",
    "       'JavaScript', 'Python', 'SQL', 'Java', 'HTML/CSS']]\n",
    "y = df['OpSys']\n",
    "\n",
    "X = pd.get_dummies(X, drop_first = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_smoted, y_smoted = SMOTE(random_state=42).fit_sample(X,y)\n",
    "\n",
    "X_train_smoted, X_test_smoted, y_train_smoted, y_test_smoted = train_test_split(X_smoted,y_smoted, test_size=0.2, \n",
    "                                                                                random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_features(X_train, y_train, basef1):\n",
    "    '''\n",
    "    A function that removes features that either raises the f1 score or only decreases it a little\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train, y_train : train data\n",
    "    basef1 : base f1 score of balanced data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    returns list of features to remove\n",
    "    '''\n",
    "    feats_remove = []\n",
    "    keep_remove = 1\n",
    "    col_list = list(X_train.columns)\n",
    "    d = {el:0 for el in col_list} #empty dictionary with col names as keys\n",
    "    \n",
    "    #loop until f1 score cannot be improved anymore\n",
    "    while keep_remove == 1:\n",
    "        \n",
    "        #loop through col_list and remove each feature, build xgboost base model and score f1\n",
    "        #put f1 score in dictionary with key of removed feature\n",
    "        for col in col_list: \n",
    "            removed = col\n",
    "            removed_col_list = col_list.copy()\n",
    "            removed_col_list.remove(removed)\n",
    "            \n",
    "            model = rf_baseline(X_train[removed_col_list], y_train)\n",
    "            d[removed] = round(cross_val_score(model, X_train[removed_col_list], y_train, scoring='f1_macro', cv=5).mean(), 2)\n",
    "        \n",
    "        #find max f1 value in dictionary \n",
    "        max_f1_key = max(d, key=d.get)\n",
    "        max_f1_val = d[max_f1_key]\n",
    "        \n",
    "        #check if max f1 is close to baseline f1 and \n",
    "        if max_f1_val >= (basef1-0.3):\n",
    "            feats_remove.append(max_f1_key)\n",
    "            col_list = col_list.remove(max_f1_key)\n",
    "            d = {el:0 for el in col_list}\n",
    "            basef1 = max_f1_val\n",
    "            print(max_f1_key, max_f1_val)\n",
    "        else:\n",
    "            keep_remove = 0\n",
    "    \n",
    "    return feats_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.62\n"
     ]
    }
   ],
   "source": [
    "rf_smoted_base = rf_baseline(X_train_smoted, y_train_smoted)\n",
    "basef1 = round(cross_val_score(rf_smoted_base, X_train_smoted, y_train_smoted, scoring='f1_macro', cv=5).mean(), 2)\n",
    "print(basef1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_remove = remove_features(X_train_smoted, y_train_smoted, basef1)\n",
    "print(feats_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_adasyn.drop(labels= feats_remove , axis=1, inplace=True)\n",
    "X_test_adasyn.drop(labels= feats_remove , axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = random_forest(X_train_smoted, y_train_smoted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose xgb_adasyn with an f1 score of: 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = xgb5_smoted.predict(X_test_smoted)\n",
    "conf = confusion_matrix(y_test_smoted, probs)\n",
    "plt.figure(figsize=(6,6))\n",
    "conf1 = sns.heatmap(conf, cmap=plt.cm.get_cmap('Blues'), annot=True, square=True, fmt='d',\n",
    "               xticklabels=['Windows', 'MacOS', 'Linux'],\n",
    "               yticklabels=['Windows', 'MacOS', 'Linux'])\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion matrix')\n",
    "conf1.figure.savefig('../Graphs/confmatrix.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score final model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1_score( y_test_smoted, probs, average='macro'))\n",
    "print(precision_score( y_test_smoted, probs, average='macro'))\n",
    "print(recall_score( y_test_smoted, probs, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../Models/xgb_balanced.pkl\", \"wb\") as f:\n",
    "#     pkl.dump(xgb5_smoted, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_adasyn.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
